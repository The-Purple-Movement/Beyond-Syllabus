---
country: "india"
university: "university-of-hyderabad"
branch: "artificial-intelligence"
scheme: "2022"
semester: 1
course_code: "ai425"
course_title: "pattern-recognition"
language: "english"
contributor: "@abhijith314"
---

# AI425: Pattern Recognition

## Prerequisite Course / Knowledge
* [cite_start]Students are expected to have knowledge of Mathematics: Calculus, Differential Equations, Linear Algebra, Probability, and Completed Programming Methodology, Programming of Scientific and Mathematical Functions[cite: 2074].

## Course Objectives
* [cite_start]CO-1: Describe the approaches to statistical and syntactic pattern recognition (Understand)[cite: 2078].
* [cite_start]CO-2: Describe the design characteristics of pattern recognitions systems such as curse of dimensionality (Understand)[cite: 2080].
* [cite_start]CO-3: Apply pattern recognition techniques to solve real world problems (Apply)[cite: 2081].
* [cite_start]CO-4: Design simple pattern classifiers, classifier combinations ad structural pattern recognizers (Create)[cite: 2082].
* CO-5: Develop pattern recognition techniques and the scientific computing environment. (Create) [cite_start][cite: 2083].

## Course Content

### Module 1: Introduction to Patterns and Recognition Methods
* [cite_start]Concepts of Pattern Recognition, applications in real world[cite: 2088].
* [cite_start]Patterns and their representations as random vectors, strings and graph, time series[cite: 2089]. [cite_start]Feature and data scales[cite: 2089].
* [cite_start]Feature and pattern similarity, dissimilarity measures[cite: 2090]. [cite_start]Feature selection, dimensionality reduction[cite: 2090]. [cite_start]PCA and SVD methods[cite: 2090].
* [cite_start]Introduction to pattern classification paradigms such as statistical, syntactical and structural pattern recognition[cite: 2091]. [cite_start]Nearest Neighbor Classification as a case study[cite: 2091].

### Module 2: Statistical Pattern Recognition
* [cite_start]Bayes decision theory, Maximum a posteriori classification, risk and errors[cite: 2092].
* [cite_start]Supervised learning using parametric and nonparametric approaches: Maximum Likelihood estimation, Bayesian parameter estimation approach, Parzen Windows, k-NN estimation[cite: 2093].

### Module 3: Linear Discriminative Classifiers
* Decision Boundaries, Separability; [cite_start]Perceptrons, Support Vector Machines, Fisher's Linear Discriminant function, Decision Trees, Random Forests, Projections and Embeddings[cite: 2094].

### Module 4: Unsupervised Learning and Other Methods
* [cite_start]Unsupervised classification, clustering: the clustering concept, clustering strategies, hierarchical clustering, Partitional clustering, c-means algorithm, learning vector quantization, expectation maximization and mean shift[cite: 2095].

### Module 5: String and Sequence Recognition Methods
* Formal languages; [cite_start]String languages for pattern recognition: selection of pattern primitives, Matching of Strings, Edit distances, pattern grammars[cite: 2096].
* [cite_start]Basic formulation of states and sequences, Markov Models, Hidden Markov Models, Viterbi Algorithm, Baum-Welch Learning[cite: 2096].
* [cite_start]Graphs fundamentals of graph theory, basic algorithms for graphs matching[cite: 2096].

## References
### Suggested Reading
1.  Duda, R.O., Hart, P.E., and Stork, D.G. *Pattern Classification*. Wiley-Interscience. 2nd Edition. [cite_start]2001[cite: 2098].
2.  [cite_start]Andrew R. Webb, and Keith D. Copsey, *Statistical Pattern Recognition*, Third Edition, Wiley-Interscience, 2011[cite: 2099].
### Other References
3.  Bishop, C. M. *Pattern Recognition and Machine Learning*. Springer. [cite_start]2007[cite: 2101].
4.  Theodoridis, S. and Koutroumbas, K. *Pattern Recognition*. [cite_start]Edition 4. Academic Press, 2008[cite: 2102].
5.  Bishop, C. M. *Neural Networks for Pattern Recognition*. Oxford University Press. [cite_start]1995[cite: 2103].
6.  Hastie, T., Tibshirani, R. and Friedman, J. *The Elements of Statistical Learning*. Springer. [cite_start]2001[cite: 2104].
7.  Koller, D. and Friedman, N. *Probabilistic Graphical Models*. MIT Press. [cite_start]2009[cite: 2105].